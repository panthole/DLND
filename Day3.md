1.	课程中我们学习到了误差函数（课程中是交叉熵）与计算误差函数最小值的方法--梯度下降法，现在我们抛开具体的交叉熵，从更为宏观的角度考察误差函数，那么有一个问题，误差函数一定越小越好吗？（注意，此处的误差函数并不特指交叉熵）
2.	这节课的最后，我们比较了梯度下降法与感知器算法的区别，请回忆一下，当分类正确时，这两种算法对边界的处理是什么样的呢？
3.	对某一点的分类正确时，这一点的梯度是较小还是较大？
4.	对某一点的分类错误时，这一点的梯度是较小还是较大？
5.	从函数图像的几何意义考虑，梯度代表了什么意思呢？
6.	本课我们学习了梯度下降，既然下降都有了，那么有没有梯度上升算法呢？请查找梯度上升算法，并找到它的用途
7.	本课我们学习梯度下降来求取误差函数的最小值，但实际使用梯度上升算法也可以求哦，请思考如何使用梯度上升法来达到本课的目标，即求误差函数最小值
8.	你知道吗，其实梯度下降算法在数学中是被分类在优化这一大类问题底下的，优化这一类问题的目的便是找到某种复合我们要求的最优解。那么请你判断一下下面这句话，并解释其为什么对或为什么错 梯度下降一定能找到全局最优解
9.	你知道吗，其实梯度下降算法在数学中是被分类在优化这一大类问题底下的，优化这一类问题的目的便是找到某种复合我们要求的最优解。那么请你判断一下下面这句话，并解释其为什么对或为什么错 梯度下降不一定能找到全局最优解
10.	你知道吗，其实梯度下降算法在数学中是被分类在优化这一大类问题底下的，优化这一类问题的目的便是找到某种复合我们要求的最优解。 请思考并回答，当我们的误差函数（代价函数）是一个非凸函数时，学习率的大小会对我们寻找全局最优解起到什么样的影响呢？
11.	在使用梯度下降时，需要进行调优。哪些地方需要调优呢？
12.	梯度下降法其实是一个大家族，你能指出我们在课堂中学习的实际是哪一种吗？
13.	梯度下降法其实是一个大家族，我们在课堂中学习的实际是批量梯度下降法，请找出其他的梯度下降法
14.	梯度下降法其实是一个大家族，我们在课堂中编程使用的实际是批量梯度下降法，请比较一下家族中其他成员与批量梯度下降的区别
15.	机器学习中的优化算法，除了梯度下降外还有很多，请试着找到他们吧

