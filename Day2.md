1.	在课程中，我们提到，在特殊情况下，softmax函数是sigmoid函数的一种对等形式，这是为什么呢？
2.	softmax函数的目标是什么？（wiki）
3.	softmax函数在神经网络中有着很大的作用，你认为一般情况下，softmax函数会被放置在神经网络的哪一层呢？
4.	one-hot编码的作用是什么呢？
5.	请你思考一下，one-hot编码前和one-hot编码后，特征发生了怎么样的变化？
6. 	我们目前看到的one-hot编码均是针对非数字特征，但是在某些数据中，为了便于收集或其他原因，我们的值也会以数字形式表示，譬如某一数据集中对于workclass这一特征，以0,1,2来表示对应等级，在这种情况下，我们还能进行one-hot编码吗？
7.	softmax函数不仅在神经网络中起着重要作用，也以不同的形式在强化学习中起着作用，你能试着找一找吗？
8.	多个sigmoid通过叠加也同样可以实现多分类的效果，那么这种叠加和softmax有什么不一样呢？
9.	本章中我们介绍了交叉熵，什么是熵呢？
10.	除了交叉熵，还有什么其他的用于神经网络分类问题的损失函数呢？
11.	最大似然率的目的是选取怎样的模型
12. 在编写感知器算法时，有一个参数--学习率，这一参数在算法中起到了什么样的作用呢？ 
13. 学习率越大越好还是越小越好呢？这是一个很困难的问题，借助最后一课的“误差之巅”，思考一下什么时候学习率的大小对我们达到误差最小的帮助 

